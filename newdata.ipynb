{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data has been stored in an excel spread sheet. Import the xlrd package to handle reading data from the excel sheet into arrays. Note: the data here is yet identified just as a cell entry and will be later converted into its actual value i.e either string or integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The output generated by the cell below is a verification for successful import. The titles of various columns are displayed as the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pubmed_id',\n",
       " 'title',\n",
       " 'abstract_text',\n",
       " 'ambiguous_penetrance',\n",
       " 'ambiguous_incidence',\n",
       " 'penetrance',\n",
       " 'incidence',\n",
       " 'polymorphism',\n",
       " 'Germline',\n",
       " 'Somatic']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import stuff\n",
    "import xlrd\n",
    "\n",
    "book      =   xlrd.open_workbook('DataSetToExportToCollboratorsMay22_2019.xlsx')\n",
    "dat_book  =   xlrd.open_workbook('CancerAKAForJoy.xlsx')\n",
    "sheet     =   book.sheet_by_index(0)\n",
    "sheet0    =   dat_book.sheet_by_index(0)\n",
    "sheet1    =   dat_book.sheet_by_index(1)\n",
    "sheet2    =   dat_book.sheet_by_index(2)\n",
    "\n",
    "#print some thing to check if import is correct\n",
    "sheet.row_values(0,end_colx=10,start_colx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imported numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#just imported it as it's always useful\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The portion commented is the download shell for stopwords provided by the nltk library. Import nltk first, remove the comment, run the download shell. Enter 'd' to enter download repository and enter 'stopwords' identifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> d\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> stopwords\n",
      "    Downloading package stopwords to C:\\Users\\Joy\n",
      "        Parikh\\AppData\\Roaming\\nltk_data...\n",
      "      Unzipping corpora\\stopwords.zip.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n"
     ]
    }
   ],
   "source": [
    "#commented below is the download interface, which I used to download the stopwords database in nltk package\n",
    "\n",
    "import nltk\n",
    "#nltk.download_shell()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the entire excel sheet which was read, colums are read into different arrays by using the slicing functionality. The main data is read in the upper paragraph and the tokenisation data is read in the lower paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The output generated from the cell below is a verification for successful slicing, the number of entries in the excel sheet can be verified with the length of array.\n",
    "\n",
    "# The entries are still identified by the code as 'cells', they will be converted to their respective values next.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6578"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slice out vlaues needed, they are still cells and not strings\n",
    "title         =   sheet.col_slice(colx=1,end_rowx=6579,start_rowx=1)\n",
    "abstract      =   sheet.col_slice(colx=2,end_rowx=6579,start_rowx=1)\n",
    "am_penetrance =   sheet.col_slice(colx=3,end_rowx=6579,start_rowx=1)\n",
    "am_incidence  =   sheet.col_slice(colx=4,end_rowx=6579,start_rowx=1)\n",
    "penetrance    =   sheet.col_slice(colx=5,end_rowx=6579,start_rowx=1)\n",
    "incidence     =   sheet.col_slice(colx=6,end_rowx=6579,start_rowx=1)\n",
    "polymorphism  =   sheet.col_slice(colx=7,end_rowx=6579,start_rowx=1)\n",
    "germline      =   sheet.col_slice(colx=8,end_rowx=6579,start_rowx=1)\n",
    "somatic       =   sheet.col_slice(colx=9,end_rowx=6579,start_rowx=1)\n",
    "\n",
    "\n",
    "\n",
    "#getting data for tokenisation\n",
    "cancer_tokens   =   sheet0.col_slice(colx=0,end_rowx=750,start_rowx=1)\n",
    "gene_tokens     =   sheet1.col_slice(colx=0,end_rowx=830,start_rowx=1)\n",
    "syndrome_tokens =   sheet2.col_slice(colx=0,end_rowx=580,start_rowx=1)\n",
    "\n",
    "len(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Each entry is is accessed and converted to it's respective value i.e the tile and abstracts are converted to strings and the classes have integer entries.\n",
    "\n",
    "# The tokens are also converted to strings. They are converted to lowercase as well. The title and abstract will also be converted to lowercase, which makes comparison of strings easier.\n",
    "\n",
    "# There is a string reversal performed, the purpose of this is to avoid missing out on larger similar strings. As the strings are traversed in a linear fashion for replacing them with tokens.\n",
    "\n",
    "# For example : The string 'Carney Complex' occurs before 'Carney Complex, Type 1' and hence instead of replacing 'Carney Complex, Type 1' with 'syndrome' it changes the string to 'syndrome, Type 1'. Reversing the order so that the largest string is compared first is the simplest manner to avoid this from happening.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert to their respective values i.e strings and integers\n",
    "for n in np.arange(len(title)):\n",
    "    title[n]           =   title[n].value\n",
    "    abstract[n]        =   abstract[n].value\n",
    "    am_penetrance[n]   =   am_penetrance[n].value\n",
    "    penetrance[n]      =   penetrance[n].value\n",
    "    am_incidence[n]    =   am_incidence[n].value\n",
    "    incidence[n]       =   incidence[n].value\n",
    "    polymorphism[n]    =   polymorphism[n].value\n",
    "    germline[n]        =   germline[n].value\n",
    "    somatic[n]         =   somatic[n].value\n",
    "    \n",
    "for n in np.arange(len(cancer_tokens)):\n",
    "    cancer_tokens[n]   =   cancer_tokens[n].value\n",
    "    (cancer_tokens[n]).lower()\n",
    "    \n",
    "for n in np.arange(len(gene_tokens)):\n",
    "    gene_tokens[n]     =   gene_tokens[n].value\n",
    "    gene_tokens[n].lower()\n",
    "    \n",
    "for n in np.arange(len(syndrome_tokens)):\n",
    "    syndrome_tokens[n] =   syndrome_tokens[n].value\n",
    "    syndrome_tokens[n].lower()\n",
    "    \n",
    "#reversed the arrays as the largest string is to be replaced first\n",
    "cancer_tokens          =   cancer_tokens[::-1]\n",
    "gene_tokens            =   gene_tokens[::-1]\n",
    "syndrome_tokens        =   syndrome_tokens[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The titles and abstracts are joined as a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combining title and abstracts\n",
    "for n in np.arange(len(title)):\n",
    "    title[n]=title[n]+' '+abstract[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data pre-processing function is declared below which is used as an analyser for the vectoriser.\n",
    "\n",
    "# The following functionalities are implemented in the function, each of which can be commented out paragraph-wise :\n",
    "\n",
    "# 1. Punctuations are removed\n",
    "# 2. Tokenisation is performed, strings matched with the ones present in the ** tokens array are replaced by ** tokens.   ** - syndrome,gene,cancer\n",
    "# 3. Consecutive, repetitive entries are removed.\n",
    "# 4. Stopwords are removed. The entries in the earlier downloaded stopwords dataset are matched and removed.\n",
    "# 5. Stemming (reduction of the word to it's root word) is performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function for preproc\n",
    "#Comment out the pre processing which is not required\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "port = PorterStemmer()\n",
    "lanc = LancasterStemmer()\n",
    "\n",
    "def text_proc(mess):\n",
    "    \n",
    "    # 1. removed punctuation\n",
    "    nopunc    =    [c for c in mess if c not in string.punctuation]\n",
    "    nopunc    =    ''.join(nopunc)\n",
    "    nopunc    =    nopunc.lower()\n",
    "    \n",
    "    \n",
    "    # 2. tokenisation\n",
    "    for n in np.arange(len(cancer_tokens)):\n",
    "        nopunc   =   nopunc.replace(cancer_tokens[n],\"cancer\")\n",
    "        \n",
    "    for n in np.arange(len(gene_tokens)):\n",
    "        nopunc   =   nopunc.replace(gene_tokens[n],\"gene\")\n",
    "        \n",
    "    for n in np.arange(len(syndrome_tokens)):\n",
    "        nopunc   =   nopunc.replace(syndrome_tokens[n],\"gene\")\n",
    "        \n",
    "        \n",
    "    # 3. remove consecutive entries\n",
    "    nopunc = re.sub(r'\\b(.+)(\\s+\\1\\b)+',r'\\1',nopunc)\n",
    "    \n",
    "    \n",
    "    # 4. removing stopwords\n",
    "    nopunc = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    \n",
    "    # 5. stemming\n",
    "    for ind in np.arange(len(nopunc)):\n",
    "        nopunc[ind] = port.stem(nopunc[ind])\n",
    "    return nopunc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard function for learning curve generation. Mentioned in the documentation for sklearn. Takes as input the classifier, Input vectors and output labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function for learning curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv =None, n_jobs=None, train_sizes=np.linspace(.1,1.0,5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X,y,cv=cv, n_jobs=n_jobs, train_sizes = train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores,axis=1)\n",
    "    train_scores_std = np.std(train_scores,axis=1)\n",
    "    test_scores_mean = np.mean(test_scores,axis=1)\n",
    "    test_scores_std = np.std(test_scores,axis=1)\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean-train_scores_std,train_scores_mean+train_scores_std,alpha=0.1,color='r')\n",
    "    plt.fill_between(train_sizes, test_scores_mean-test_scores_std,test_scores_mean+test_scores_std,alpha=0.1,color='g')\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-',color='r',label=\"Training Score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-',color='g',label=\"CV Score\")\n",
    "    \n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following tasks are to performed on the dataset provided. \n",
    "\n",
    "# 1. From the arrays corresponding to columns, entries which have a '1' in ambiguous_penetrance or ambiguous_incidences are to be removed. The remaining entries are to be used as dataset to classify into somatic and to classify into germline\n",
    "\n",
    "# 2. The germline entries from dataset in (1) are kept, which are used to classify into polymorphism.\n",
    "\n",
    "# 3. The non-polymorphism entries from dataset in (2) are kept, which are used to classify into penetrance and into incidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following is implementation where entries with ambiguous_penetrance or ambiguous_incidence = 1 are removed. title1, label1, label2 are the remaining dataset corresponding to title, somatic and germline.\n",
    "\n",
    "# The output of the cell is to verify deletion of entries. Length of title1 is lesser than that of title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6342"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### Implementation 1\n",
    "\n",
    "indicesp     =     [i for i in np.arange(len(am_penetrance)) if am_penetrance[i]==1]\n",
    "indicesi     =     [i for i in np.arange(len(am_incidence)) if am_incidence[i]==1]\n",
    "indices      =     np.union1d(indicesp,indicesi)\n",
    "title1       =     np.delete(title,indices)\n",
    "label1       =     np.delete(somatic,indices)\n",
    "label2       =     np.delete(germline,indices)\n",
    "\n",
    "#checking length to see if deletion works\n",
    "len(title1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following cell is an extra verification which prints the number of entries which were to be removed. len(title) = len(title1) + len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of entries deleted\n",
    "len(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All useful stuff for classification from the sklearn library is imported here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting everything I need for classification\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BaseDiscreteNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import BaseNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from skmultilearn.adapt import MLkNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following is where classifier is built. \n",
    "# 1. As the best possible parameter from a user provided range has to be selected, the gridsearchcv functionality is used which executes multiple training folds with different parameter combinations and generates the best_estimator\n",
    "# 2. A pipeline is built which performs the essential tasks in an order. The CountVectorizer uses our custom text_proc function to generate a bag-of-words from the string fed to it and vectorising them. The tfidfTransformer generates vectors based on the terms frequence and inverse-document-frequency. Classifier is directed to the grid as we are searching for best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For using a new classifier:\n",
    "# 1. MultinomialNB\n",
    "#             Replace\n",
    "\n",
    "param_gd1 = {'alpha':[]}  (filling the parameter values in the square brackets)\n",
    "\n",
    "#             Replace \n",
    "\n",
    "grid1 = GridSearchCV(MultinomialNB(),param_gd1,verbose=3)\n",
    "\n",
    "# 2. BernoulliNB\n",
    "#             Replace \n",
    "\n",
    "param_gd1 = {'alpha':[]}  (filling the parameter values in the square brackets)\n",
    "\n",
    "#             Replace \n",
    "\n",
    "grid1 = GridSearchCV(BernoulliNB(),param_gd1,verbose=3)\n",
    "\n",
    "# 3. RandomForest\n",
    "#             Replace \n",
    "\n",
    "param_gd1 = {'n_estimators':[3,10,30], 'max_features':[2,4,6,8]}  (filling the parameter values in the square brackets)\n",
    "\n",
    "#             Replace \n",
    "\n",
    "grid1 = GridSearchCV(RandomForestClassifier(),param_gd1,verbose=3)\n",
    "\n",
    "# 4. Logistic Regression\n",
    "#             Replace \n",
    "\n",
    "param_gd1 = {'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}  (filling the parameter values in the square brackets)\n",
    "\n",
    "#             Replace \n",
    "\n",
    "grid1 = GridSearchCV(LogisticRegression(),param_gd1,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "param_gd1     =     {'C':[1,10,100],'gamma':[0.1,1,0.01]} \n",
    "param_gd2     =     {'C':[1,10,100],'gamma':[0.1,1,0.01]} \n",
    "grid1         =     GridSearchCV(SVC(),param_gd1,verbose=3)\n",
    "grid2         =     GridSearchCV(SVC(),param_gd2,verbose=3)\n",
    "\n",
    "#one pipeline for somatic classification\n",
    "pipeline_s = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_proc)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',grid1)\n",
    "])\n",
    "\n",
    "\n",
    "#one pipeline for germline classification\n",
    "pipeline_g = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_proc)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',grid2)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dataset into training and testing dataset(10% testing size) using train_test split to keep it random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generating training and testing data\n",
    "title_tr_s,  title_te_s,  label_tr_s,  label_te_s   =   train_test_split(title1,label1,test_size=0.1)\n",
    "title_tr_g,  title_te_g,  label_tr_g,  label_te_g   =   train_test_split(title1,label2,test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the training dataset into the pipeline i.e creating bow, creating vectors, getting tf-idf and classifying these vectors into labels provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] .......... C=1, gamma=0.1, score=0.860746190225959, total=  41.6s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=1, gamma=0.1, score=0.8811777076761304, total=  47.9s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=1, gamma=0.1, score=0.8717139852786541, total=  53.4s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.8754598003152917, total= 1.4min\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.8958990536277602, total= 1.3min\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.8911671924290221, total= 1.2min\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.7272727272727273, total=  55.6s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.7271293375394322, total=  56.7s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.7271293375394322, total=  56.2s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.8807146610614819, total=  31.7s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.8932702418506835, total=  53.8s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .......... C=10, gamma=0.1, score=0.88801261829653, total=  52.7s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.8775617446137677, total= 1.4min\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.8980021030494216, total= 1.4min\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.8885383806519453, total= 1.4min\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.8617971623751971, total=  51.1s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.8843322818086226, total=  41.8s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.8743427970557308, total=  53.7s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ....... C=100, gamma=0.1, score=0.8765107724645297, total= 1.2min\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ....... C=100, gamma=0.1, score=0.8853838065194533, total= 1.2min\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ....... C=100, gamma=0.1, score=0.8664563617245006, total= 1.1min\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ......... C=100, gamma=1, score=0.8775617446137677, total= 1.3min\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ......... C=100, gamma=1, score=0.8980021030494216, total= 1.4min\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ......... C=100, gamma=1, score=0.8885383806519453, total= 1.4min\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ...... C=100, gamma=0.01, score=0.8801891749868629, total=  46.1s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ...... C=100, gamma=0.01, score=0.8901156677181914, total=  44.9s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ...... C=100, gamma=0.01, score=0.8848580441640379, total=  46.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 45.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.8812401471361009, total=  29.7s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   54.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=1, gamma=0.1, score=0.8664563617245006, total=  36.4s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=1, gamma=0.1, score=0.8648790746582544, total=  36.3s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.9022595901208618, total=  35.7s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.8780231335436383, total=  45.7s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.8769716088328076, total=  46.3s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.7535470310036784, total=  19.6s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.7539432176656151, total=  40.1s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.7539432176656151, total=  27.4s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.8880714661061482, total=  30.7s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ......... C=10, gamma=0.1, score=0.879074658254469, total=  29.9s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.8759200841219769, total=  34.9s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.9012086179716238, total=  48.2s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.8874868559411146, total=  57.2s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.8838065194532071, total=  58.4s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.8864950078822911, total=  33.9s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.8680336487907466, total=  26.2s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ........ C=10, gamma=0.01, score=0.868559411146162, total=  37.6s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ....... C=100, gamma=0.1, score=0.8885969521807672, total=  35.9s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ....... C=100, gamma=0.1, score=0.8764458464773922, total=  32.8s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ....... C=100, gamma=0.1, score=0.8722397476340694, total=  34.8s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ......... C=100, gamma=1, score=0.9012086179716238, total=  52.2s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ......... C=100, gamma=1, score=0.8874868559411146, total=  53.5s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ......... C=100, gamma=1, score=0.8838065194532071, total= 1.1min\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ...... C=100, gamma=0.01, score=0.8849185496584341, total=  37.7s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ...... C=100, gamma=0.01, score=0.8769716088328076, total=  34.8s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ...... C=100, gamma=0.01, score=0.8764458464773922, total=  41.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 29.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer=<function text_proc at 0x000001CF533A2158>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=N...   pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the training data into the classifier model\n",
    "pipeline_s.fit(title_tr_s,label_tr_s)\n",
    "pipeline_g.fit(title_tr_g,label_tr_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For getting metrics for classifier performance, run the implementation below. It fits the testing dataset into classifier and predicts labels, which are compared to actual labels.\n",
    "#  replace  : \n",
    "    #  pipeline_s = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_proc)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',grid1.best_estimator_)\n",
    "      ])\n",
    "# Then run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.72      0.78      0.75       135\n",
      "        1.0       0.94      0.92      0.93       500\n",
      "\n",
      "avg / total       0.89      0.89      0.89       635\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#som = pipeline_s.predict(title_te_s)\n",
    "germ = pipeline_g.predict(title_te_g)\n",
    "#print(classification_report(som,label_te_s))\n",
    "print(classification_report(germ,label_te_g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To prompt the best estimator and corresponding parameters, run the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prompts the best performing parameters from the parameter grid in gridsearch\n",
    "grid1.best_estimator_\n",
    "grid2.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following is implementation where entries with germline = 0 are removed. title2, labelf are the remaining dataset corresponding to title and polymorphism.\n",
    "\n",
    "# The output of the cell is to verify deletion of entries. Length of title2 is lesser than that of title and title1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4777"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########  Implementation 2\n",
    "indices2 = [i for i in np.arange(len(label2)) if label2[i]==0]\n",
    "title2 = np.delete(title1,indices2)\n",
    "labelt = np.delete(polymorphism,indices)\n",
    "labelf = np.delete(labelt,indices2)\n",
    "#checking if deletion worked\n",
    "len(title2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For using a new classifier:\n",
    "# 1. MultinomialNB\n",
    "#             Replace\n",
    "\n",
    "param_gdp = {'alpha':[]}  (filling the parameter values in the square brackets)\n",
    "\n",
    "#             Replace \n",
    "\n",
    "gridp = GridSearchCV(MultinomialNB(),param_gdp,verbose=3)\n",
    "\n",
    "# 2. BernoulliNB\n",
    "#             Replace \n",
    "\n",
    "param_gdp = {'alpha':[]}  (filling the parameter values in the square brackets)\n",
    "\n",
    "#             Replace \n",
    "\n",
    "gridp = GridSearchCV(BernoulliNB(),param_gdp,verbose=3)\n",
    "\n",
    "# 3. RandomForest\n",
    "#             Replace \n",
    "\n",
    "param_gdp = {'n_estimators':[3,10,30], 'max_features':[2,4,6,8]}  (filling the parameter values in the square brackets)\n",
    "\n",
    "#             Replace \n",
    "\n",
    "gridp = GridSearchCV(RandomForestClassifier(),param_gdp,verbose=3)\n",
    "\n",
    "# 4. Logistic Regression\n",
    "#             Replace \n",
    "\n",
    "param_gdp = {'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}  (filling the parameter values in the square brackets)\n",
    "\n",
    "#             Replace \n",
    "\n",
    "gridp = GridSearchCV(LogisticRegression(),param_gdp,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pipeline for polymorphism classifier\n",
    "\n",
    "param_gdp      =     {'C':[10,100,1000],'gamma':[0.1,0.01,0.001]} \n",
    "gridp          =     GridSearchCV(SVC(),param_gdp,verbose=3)\n",
    "\n",
    "\n",
    "pipeline_p = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_proc)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',gridp)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dataset into training and testing dataset(10% testing size) using train_test split to keep it random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generating training and testing data for polymorphism classification\n",
    "title_tr_p,  title_te_p,  label_tr_p,  label_te_p   =   train_test_split(title2,labelf,test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the training dataset into the pipeline i.e creating bow, creating vectors, getting tf-idf and classifying these vectors into labels provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.9673571876961707, total=  13.5s\n",
      "[CV] C=10, gamma=0.1 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   21.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=10, gamma=0.1, score=0.9660804020100503, total=  11.8s\n",
      "[CV] C=10, gamma=0.1 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   41.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=10, gamma=0.1, score=0.9692211055276382, total=  11.6s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.9516635279347144, total=  11.9s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.9409547738693468, total=  12.8s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.9491206030150754, total=  12.2s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.9108600125549278, total=  12.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.9108040201005025, total=  12.4s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.9108040201005025, total=  11.6s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ........ C=100, gamma=0.1, score=0.967984934086629, total=  12.9s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ....... C=100, gamma=0.1, score=0.9623115577889447, total=  12.0s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ....... C=100, gamma=0.1, score=0.9685929648241206, total=  14.0s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ....... C=100, gamma=0.01, score=0.967984934086629, total=  10.0s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ...... C=100, gamma=0.01, score=0.9641959798994975, total=  11.2s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ...... C=100, gamma=0.01, score=0.9704773869346733, total=  12.1s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ..... C=100, gamma=0.001, score=0.9516635279347144, total=  12.3s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ..... C=100, gamma=0.001, score=0.9409547738693468, total=  12.2s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ..... C=100, gamma=0.001, score=0.9510050251256281, total=  11.0s\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ....... C=1000, gamma=0.1, score=0.967984934086629, total=  11.5s\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ...... C=1000, gamma=0.1, score=0.9623115577889447, total=  12.2s\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ...... C=1000, gamma=0.1, score=0.9685929648241206, total=  12.9s\n",
      "[CV] C=1000, gamma=0.01 ..............................................\n",
      "[CV] ..... C=1000, gamma=0.01, score=0.9667294413057125, total=  11.9s\n",
      "[CV] C=1000, gamma=0.01 ..............................................\n",
      "[CV] ...... C=1000, gamma=0.01, score=0.960427135678392, total=  10.6s\n",
      "[CV] C=1000, gamma=0.01 ..............................................\n",
      "[CV] ..... C=1000, gamma=0.01, score=0.9673366834170855, total=  11.8s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] ..... C=1000, gamma=0.001, score=0.967984934086629, total=  11.1s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .... C=1000, gamma=0.001, score=0.9635678391959799, total=  11.6s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .... C=1000, gamma=0.001, score=0.9704773869346733, total=  12.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  8.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer=<function text_proc at 0x000001CF533A2158>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=N...   pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the training data into classifier model\n",
    "pipeline_p.fit(title2,labelf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For getting metrics for classifier performance, run the implementation below. It fits the testing dataset into classifier and predicts labels, which are compared to actual labels.\n",
    "#  replace  : \n",
    "    #  pipeline_p = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_proc)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',gridp.best_estimator_)\n",
    "      ])\n",
    "# Then run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00       434\n",
      "        1.0       1.00      0.98      0.99        44\n",
      "\n",
      "avg / total       1.00      1.00      1.00       478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fits the testing data and generates a classification report for predicted v/s actual values\n",
    "poly     =     pipeline_p.predict(title_te_p)\n",
    "print(classification_report(poly,label_te_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To prompt the best estimator and corresponding parameters, run the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.1}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prompts the best performing parameters for polymorphism classification\n",
    "gridp.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following is implementation where entries with polymorphism = 1 are removed. title3, label_i,label_p are the remaining dataset corresponding to title, incidence and penetrance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ Implementation 3\n",
    "indices3 = [i for i in np.arange(len(labelf)) if labelf[i]==1]\n",
    "title3 = np.delete(title2,indices3)\n",
    "label_i_1 = np.delete(incidence,indices)\n",
    "label_p_1 = np.delete(penetrance,indices)\n",
    "label_i_2 = np.delete(label_i_1,indices2)\n",
    "label_p_2 = np.delete(label_p_1,indices2)\n",
    "label_i = np.delete(label_i_2,indices3)\n",
    "label_p = np.delete(label_p_2,indices3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For using a new classifier:\n",
    "# 1. MultinomialNB\n",
    "#             Replace\n",
    "\n",
    "param_gdpe = {'alpha':[]}  (filling the parameter values in the square brackets)\n",
    "\n",
    "#             Replace \n",
    "\n",
    "gridpe = GridSearchCV(MultinomialNB(),param_gdpe,verbose=3)\n",
    "\n",
    "# 2. BernoulliNB\n",
    "#             Replace \n",
    "\n",
    "param_gdpe = {'alpha':[]}  (filling the parameter values in the square brackets)\n",
    "\n",
    "#             Replace \n",
    "\n",
    "gridpe = GridSearchCV(BernoulliNB(),param_gdpe,verbose=3)\n",
    "\n",
    "# 3. RandomForest\n",
    "#             Replace \n",
    "\n",
    "param_gdpe = {'n_estimators':[3,10,30], 'max_features':[2,4,6,8]}  (filling the parameter values in the square brackets)\n",
    "\n",
    "#             Replace \n",
    "\n",
    "gridpe = GridSearchCV(RandomForestClassifier(),param_gdpe,verbose=3)\n",
    "\n",
    "# 4. Logistic Regression\n",
    "#             Replace \n",
    "\n",
    "param_gdpe = {'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}  (filling the parameter values in the square brackets)\n",
    "\n",
    "#             Replace \n",
    "\n",
    "gridpe = GridSearchCV(LogisticRegression(),param_gdpe,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters for respective classifiers are added as a dictionary here\n",
    "param_gdpe      =      {'C':[0.1,1,10,100],'gamma':[0.1,1,0.01,0.001]} \n",
    "gridpe          =      GridSearchCV(SVC(),param_gdpe,verbose=3)\n",
    "\n",
    "#pipeline for penetrance classification\n",
    "pipeline_pe = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_proc)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',gridpe)\n",
    "])\n",
    "\n",
    "\n",
    "#pipeline for incidence classification\n",
    "param_gdi       =      {'C':[1,10,100,1000],'gamma':[0.1,1,10,100]} \n",
    "gridi           =      GridSearchCV(SVC(),param_gdi,verbose=3)\n",
    "\n",
    "pipeline_i = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_proc)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',gridi)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dataset into training and testing dataset(10% testing size) using train_test split to keep it random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generating training and testing data for classification\n",
    "title_tr_pe,  title_te_pe,  label_tr_pe,  label_te_pe   =   train_test_split(title3,label_p,test_size=0.1)\n",
    "title_tr_i,   title_te_i,   label_tr_i,   label_te_i    =   train_test_split(title3,label_i,test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the training dataset into the pipeline i.e creating bow, creating vectors, getting tf-idf and classifying these vectors into labels provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.7426239799121155, total=  28.4s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   47.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... C=0.1, gamma=0.1, score=0.7426239799121155, total=  30.1s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=0.1, gamma=0.1, score=0.742928975487115, total=  25.7s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.7457627118644068, total=  30.6s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.7432517263025737, total=  31.5s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] .......... C=0.1, gamma=1, score=0.742928975487115, total=  32.5s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ...... C=0.1, gamma=0.01, score=0.7426239799121155, total=  25.5s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ...... C=0.1, gamma=0.01, score=0.7426239799121155, total=  27.4s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ....... C=0.1, gamma=0.01, score=0.742928975487115, total=  22.2s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ..... C=0.1, gamma=0.001, score=0.7426239799121155, total=  25.3s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ..... C=0.1, gamma=0.001, score=0.7426239799121155, total=  17.8s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ...... C=0.1, gamma=0.001, score=0.742928975487115, total=  23.8s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.8493408662900188, total=  26.8s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.8549905838041432, total=  25.9s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.8120678818353237, total=  24.5s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.8600125549278091, total=  34.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.8750784682988073, total=  33.4s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ............ C=1, gamma=1, score=0.830923947203017, total=  19.2s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.7426239799121155, total=  27.9s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.7426239799121155, total=  29.4s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ......... C=1, gamma=0.01, score=0.742928975487115, total=  28.3s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....... C=1, gamma=0.001, score=0.7426239799121155, total=  25.3s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....... C=1, gamma=0.001, score=0.7426239799121155, total=  28.5s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ........ C=1, gamma=0.001, score=0.742928975487115, total=  26.3s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.8631512868801005, total=  23.5s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.8775894538606404, total=  25.3s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.8598365807668134, total=  24.1s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ........... C=10, gamma=1, score=0.869428750784683, total=  32.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.8813559322033898, total=  36.2s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.8403519798868636, total=  35.5s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.8562460765850597, total=  24.1s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.8612680477087257, total=  22.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ........ C=10, gamma=0.01, score=0.819610307982401, total=  23.7s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.7426239799121155, total=  29.5s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.7426239799121155, total=  21.7s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ....... C=10, gamma=0.001, score=0.742928975487115, total=  24.9s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ....... C=100, gamma=0.1, score=0.8575015693659761, total=  15.4s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ......... C=100, gamma=0.1, score=0.86691776522285, total=  14.0s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ....... C=100, gamma=0.1, score=0.8497800125707102, total=  24.3s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] .......... C=100, gamma=1, score=0.869428750784683, total=  43.9s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ......... C=100, gamma=1, score=0.8813559322033898, total=  42.6s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ......... C=100, gamma=1, score=0.8403519798868636, total=  33.4s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ...... C=100, gamma=0.01, score=0.8625235404896422, total=  24.1s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ...... C=100, gamma=0.01, score=0.8738229755178908, total=  22.6s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ...... C=100, gamma=0.01, score=0.8604651162790697, total=  22.2s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ..... C=100, gamma=0.001, score=0.8549905838041432, total=  25.6s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ..... C=100, gamma=0.001, score=0.8612680477087257, total=  27.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ..... C=100, gamma=0.001, score=0.8202388434946575, total=  23.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed: 35.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.7897049591964846, total=  23.9s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   42.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=1, gamma=0.1, score=0.805398618957941, total=  32.7s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=1, gamma=0.1, score=0.7894406033940917, total=  31.4s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.7984934086629002, total=  36.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.8192090395480226, total=  37.8s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.7875549968573224, total=  35.7s\n",
      "[CV] C=1, gamma=10 ...................................................\n",
      "[CV] ........... C=1, gamma=10, score=0.591337099811676, total=  45.0s\n",
      "[CV] C=1, gamma=10 ...................................................\n",
      "[CV] ........... C=1, gamma=10, score=0.591337099811676, total=  50.4s\n",
      "[CV] C=1, gamma=10 ...................................................\n",
      "[CV] .......... C=1, gamma=10, score=0.5914519170333123, total=  47.8s\n",
      "[CV] C=1, gamma=100 ..................................................\n",
      "[CV] .......... C=1, gamma=100, score=0.591337099811676, total=  51.3s\n",
      "[CV] C=1, gamma=100 ..................................................\n",
      "[CV] .......... C=1, gamma=100, score=0.591337099811676, total=  42.1s\n",
      "[CV] C=1, gamma=100 ..................................................\n",
      "[CV] ......... C=1, gamma=100, score=0.5914519170333123, total=  49.9s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.7966101694915254, total=  25.8s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ......... C=10, gamma=0.1, score=0.802887633396108, total=  30.1s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.7649277184160905, total=  26.1s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.7997489014438167, total=  23.9s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.8123038292529818, total=  45.4s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.7825267127592709, total=  32.0s\n",
      "[CV] C=10, gamma=10 ..................................................\n",
      "[CV] .......... C=10, gamma=10, score=0.591337099811676, total=  50.8s\n",
      "[CV] C=10, gamma=10 ..................................................\n",
      "[CV] .......... C=10, gamma=10, score=0.591337099811676, total=  51.9s\n",
      "[CV] C=10, gamma=10 ..................................................\n",
      "[CV] ......... C=10, gamma=10, score=0.5914519170333123, total=  45.4s\n",
      "[CV] C=10, gamma=100 .................................................\n",
      "[CV] ......... C=10, gamma=100, score=0.591337099811676, total=  45.0s\n",
      "[CV] C=10, gamma=100 .................................................\n",
      "[CV] ......... C=10, gamma=100, score=0.591337099811676, total=  51.4s\n",
      "[CV] C=10, gamma=100 .................................................\n",
      "[CV] ........ C=10, gamma=100, score=0.5914519170333123, total=  52.2s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ....... C=100, gamma=0.1, score=0.7978656622724419, total=  20.1s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ....... C=100, gamma=0.1, score=0.7934714375392341, total=  35.9s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ....... C=100, gamma=0.1, score=0.7492143306096795, total=  19.6s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ......... C=100, gamma=1, score=0.7997489014438167, total=  24.6s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ......... C=100, gamma=1, score=0.8123038292529818, total=  46.4s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ......... C=100, gamma=1, score=0.7825267127592709, total=  26.9s\n",
      "[CV] C=100, gamma=10 .................................................\n",
      "[CV] ......... C=100, gamma=10, score=0.591337099811676, total=  49.0s\n",
      "[CV] C=100, gamma=10 .................................................\n",
      "[CV] ......... C=100, gamma=10, score=0.591337099811676, total=  45.6s\n",
      "[CV] C=100, gamma=10 .................................................\n",
      "[CV] ........ C=100, gamma=10, score=0.5914519170333123, total=  49.5s\n",
      "[CV] C=100, gamma=100 ................................................\n",
      "[CV] ........ C=100, gamma=100, score=0.591337099811676, total=  48.9s\n",
      "[CV] C=100, gamma=100 ................................................\n",
      "[CV] ........ C=100, gamma=100, score=0.591337099811676, total=  53.7s\n",
      "[CV] C=100, gamma=100 ................................................\n",
      "[CV] ....... C=100, gamma=100, score=0.5914519170333123, total=  52.8s\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ...... C=1000, gamma=0.1, score=0.7978656622724419, total=  25.2s\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ...... C=1000, gamma=0.1, score=0.7934714375392341, total=  36.1s\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ...... C=1000, gamma=0.1, score=0.7492143306096795, total=  19.0s\n",
      "[CV] C=1000, gamma=1 .................................................\n",
      "[CV] ........ C=1000, gamma=1, score=0.7997489014438167, total=  43.5s\n",
      "[CV] C=1000, gamma=1 .................................................\n",
      "[CV] ........ C=1000, gamma=1, score=0.8123038292529818, total=  42.2s\n",
      "[CV] C=1000, gamma=1 .................................................\n",
      "[CV] ........ C=1000, gamma=1, score=0.7825267127592709, total=  47.1s\n",
      "[CV] C=1000, gamma=10 ................................................\n",
      "[CV] ........ C=1000, gamma=10, score=0.591337099811676, total=  55.1s\n",
      "[CV] C=1000, gamma=10 ................................................\n",
      "[CV] ........ C=1000, gamma=10, score=0.591337099811676, total=  54.3s\n",
      "[CV] C=1000, gamma=10 ................................................\n",
      "[CV] ....... C=1000, gamma=10, score=0.5914519170333123, total=  53.9s\n",
      "[CV] C=1000, gamma=100 ...............................................\n",
      "[CV] ....... C=1000, gamma=100, score=0.591337099811676, total=  52.1s\n",
      "[CV] C=1000, gamma=100 ...............................................\n",
      "[CV] ....... C=1000, gamma=100, score=0.591337099811676, total=  51.9s\n",
      "[CV] C=1000, gamma=100 ...............................................\n",
      "[CV] ...... C=1000, gamma=100, score=0.5914519170333123, total=  51.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed: 52.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer=<function text_proc at 0x000001CF533A2158>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=N...   pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the training data into the classifier model\n",
    "pipeline_pe.fit(title3,label_p)\n",
    "pipeline_i.fit(title3,label_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For getting metrics for classifier performance, run the implementation below. It fits the testing dataset into classifier and predicts labels, which are compared to actual labels.\n",
    "#  replace  : \n",
    "    #  pipeline_pe = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_proc)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',gridpe.best_estimator_)\n",
    "      ])\n",
    "      \n",
    "    #  pipeline_i = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_proc)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',gridi.best_estimator_)\n",
    "      ])\n",
    "      \n",
    "# Then run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.98       344\n",
      "        1.0       0.96      0.96      0.96       134\n",
      "\n",
      "avg / total       0.98      0.98      0.98       478\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00       265\n",
      "        1.0       1.00      1.00      1.00       213\n",
      "\n",
      "avg / total       1.00      1.00      1.00       478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#generated a classification report for predicted v/s actual testing data\n",
    "pen     =     pipeline_pe.predict(title_te_pe)\n",
    "inc     =     pipeline_i.predict(title_te_i)\n",
    "print(classification_report(pen,label_te_pe))\n",
    "print(classification_report(inc,label_te_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To prompt the best estimator and corresponding parameters, run the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prompts the best performing parameters for the clasifier model\n",
    "#gridpe.best_estimator_\n",
    "gridi.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generating a vector of frequencies and inverse document frequencies for implementation 1\n",
    "bow_tr = CountVectorizer(analyzer=text_proc).fit(title1)\n",
    "mess_bow = bow_tr.transform(title1);\n",
    "tfidf_tr = TfidfTransformer().fit(mess_bow)\n",
    "mess_tfidf = tfidf_tr.transform(mess_bow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generating a vector of frequencies and inverse document frequencies for implementation 2\n",
    "bow_tr2 = CountVectorizer(analyzer=text_proc).fit(title2)\n",
    "mess_bow2 = bow_tr2.transform(title2);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generating a vector of frequencies and inverse document frequencies for implementation 2\n",
    "tfidf_tr2 = TfidfTransformer().fit(mess_bow2)\n",
    "mess_tfidf2 = tfidf_tr2.transform(mess_bow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generating a vector of frequencies and inverse document frequencies for implementation 3\n",
    "bow_tr3 = CountVectorizer(analyzer=text_proc).fit(title3)\n",
    "mess_bow3= bow_tr3.transform(title3);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generating a vector of frequencies and inverse document frequencies for implementation 3\n",
    "tfidf_tr3 = TfidfTransformer().fit(mess_bow3)\n",
    "mess_tfidf3 = tfidf_tr3.transform(mess_bow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLFgYY4zx9f8BrcrP0GzF8OQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#generates learning curves based on vector and esetimator fed. So get the best estimator parameters, declare an estimator\n",
    "#here and pass the required data into the plot_learning_curve function\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "title = \"LearningCurve SVM germline C = 10 gamma =1\" \n",
    "cv = ShuffleSplit(n_splits=10,test_size=0.2, random_state=0)\n",
    "estimator = SVC(C=10,gamma=1)\n",
    "plot_learning_curve(estimator,title,mess_tfidf,label2,ylim=(0.7,1.01),cv=cv,n_jobs=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting all of this into a single function which predicts classes based on the trained models :"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
